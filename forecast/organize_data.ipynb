{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2373bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e23d81",
   "metadata": {},
   "source": [
    "## In this notebook is saved the code to gen the dataframes to apply the LSTM model for the states and \"Macroregionais de saúde\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1117c9",
   "metadata": {},
   "source": [
    "Path where the cases and climate data are saved:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1340a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/eduardoaraujo/Documents/Github/paper-dengue-sc/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47183f",
   "metadata": {},
   "source": [
    "The dataframe below will be used in the functions to get the link between the geocodes and the health macroregion code: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee86217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geocode</th>\n",
       "      <th>name_muni</th>\n",
       "      <th>name_region</th>\n",
       "      <th>code_region</th>\n",
       "      <th>name_macro</th>\n",
       "      <th>code_macro</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100015</td>\n",
       "      <td>Alta Floresta D'Oeste</td>\n",
       "      <td>Zona da Mata</td>\n",
       "      <td>11005</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>1101</td>\n",
       "      <td>RO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100023</td>\n",
       "      <td>Ariquemes</td>\n",
       "      <td>Vale do Jamari</td>\n",
       "      <td>11001</td>\n",
       "      <td>Porto Velho</td>\n",
       "      <td>1102</td>\n",
       "      <td>RO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100031</td>\n",
       "      <td>Cabixi</td>\n",
       "      <td>Cone Sul</td>\n",
       "      <td>11006</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>1101</td>\n",
       "      <td>RO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100049</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>Café</td>\n",
       "      <td>11002</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>1101</td>\n",
       "      <td>RO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100056</td>\n",
       "      <td>Cerejeiras</td>\n",
       "      <td>Cone Sul</td>\n",
       "      <td>11006</td>\n",
       "      <td>Cacoal</td>\n",
       "      <td>1101</td>\n",
       "      <td>RO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geocode              name_muni     name_region  code_region   name_macro  \\\n",
       "0  1100015  Alta Floresta D'Oeste    Zona da Mata        11005       Cacoal   \n",
       "1  1100023              Ariquemes  Vale do Jamari        11001  Porto Velho   \n",
       "2  1100031                 Cabixi        Cone Sul        11006       Cacoal   \n",
       "3  1100049                 Cacoal            Café        11002       Cacoal   \n",
       "4  1100056             Cerejeiras        Cone Sul        11006       Cacoal   \n",
       "\n",
       "   code_macro state  \n",
       "0        1101    RO  \n",
       "1        1102    RO  \n",
       "2        1101    RO  \n",
       "3        1101    RO  \n",
       "4        1101    RO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('../macro_saude.csv')\n",
    "\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57de50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geocodes_and_state(macro): \n",
    "    '''\n",
    "    This function is used to get the geocodes and state that refer to a specific health macro region code\n",
    "    \n",
    "    :param macro:int. A four-digit number\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    dfs = pd.read_csv('../macro_saude.csv')\n",
    "    \n",
    "    geocodes = dfs.loc[dfs.code_macro == macro].geocode.unique()\n",
    "    state = dfs.loc[dfs.code_macro == macro].state.values[0]\n",
    "\n",
    "    return geocodes, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47b5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_geocodes(geocodes):\n",
    "    \n",
    "    '''\n",
    "    This function split the geocodes between the cities with populations up and below 30k in 2022.\n",
    "    \n",
    "    :param geocode:list of int. A list with seven-digit ibge codes for brazilian cities \n",
    "     \n",
    "    '''\n",
    "    \n",
    "    dfpop = pd.read_csv('poptcu2010-2022_rgi.csv')\n",
    "\n",
    "    g_low = dfpop.loc[ (dfpop.CODMUN7.isin(geocodes)) & (dfpop.POP22 <= 30000) ].CODMUN7.unique()\n",
    "    \n",
    "    g_up = np.setdiff1d(geocodes, g_low)\n",
    "    \n",
    "    if geocodes.shape[0] != g_low.shape[0] + g_up.shape[0]:\n",
    "    \n",
    "        print('Error subtracting geocodes')\n",
    "    \n",
    "    return g_up, g_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8e08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, geocode, geo_col = 'municipio_geocodigo'): \n",
    "    '''\n",
    "    This filters the data for a specific region and returns it as a separate dataframe.\n",
    "    \n",
    "    :param df: pd.DataFrame.\n",
    "    :param geocode:. Must be at the same type of the geo_col \n",
    "    :param geo_col: str. Name of the column in the df that it will be used to filter the geocode value\n",
    "     \n",
    "    '''\n",
    "        \n",
    "    \n",
    "    df_ep = df.loc[df[geo_col] == geocode]\n",
    "    \n",
    "    del df_ep[geo_col]\n",
    "    \n",
    "    df_ep.columns = df_ep.columns + f'_{geocode}'\n",
    "    \n",
    "    return df_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115cd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_clim = ['temp_min', 'temp_max', 'umid_min', 'umid_max',\n",
    "                   'pressao_min', 'pressao_max', 'precip_tot', 'rainy_days',\n",
    "                   'temp_mean', 'temp_amp','umid_mean','umid_amp',\n",
    "                   'pressao_mean']\n",
    "def predictors_ep_macro(macro): \n",
    "    '''\n",
    "    This function is used to organize in a table the epidemiological predictors related to a specific health macroregion\n",
    "    \n",
    "    :params macro: int. A four digit number\n",
    "    '''\n",
    "    \n",
    "    geocodes, state = get_geocodes_and_state(macro)\n",
    "\n",
    "    # get epidemiological factors \n",
    "    df_ep = pd.read_parquet(f'{PATH}/cases/{state}_dengue.parquet',\n",
    "                           columns = ['data_iniSE', 'casos', 'municipio_geocodigo', 'p_rt1', 'Rt', 'p_inc100k'])\n",
    "    \n",
    "    # select only the geocodes include in the health macroregion\n",
    "    df_ep = df_ep.loc[df_ep.municipio_geocodigo.isin(geocodes)]\n",
    "    \n",
    "    df_ep = df_ep.sort_index()\n",
    "    \n",
    "    # split the geocodes between cities with population up and below 30k in 2022\n",
    "    g_up, g_low = split_geocodes(geocodes)    \n",
    "\n",
    "    # get the data of each city with population above 30k\n",
    "    list_data_ep = []\n",
    "\n",
    "    for g in g_up:\n",
    "\n",
    "        list_data_ep.append(transform_data(df_ep, g))\n",
    "    \n",
    "    # get the total weekly cases of this health macroregion \n",
    "    data_macro_ep = df_ep[['casos']].resample('W-SUN').sum()#.agg({'casos':np.sum, \n",
    "                                                      #'p_rt1': np.mean, \n",
    "                                                      #'Rt': np.mean})\n",
    "\n",
    "    data_macro_ep.columns = data_macro_ep.columns + f'_{macro}'\n",
    "\n",
    "    list_data_ep.append(data_macro_ep)\n",
    "    \n",
    "    \n",
    "    # aggregate the data from small cities\n",
    "    \n",
    "    data_small_cities = df_ep.loc[df_ep.municipio_geocodigo.isin(g_low)][['casos','p_rt1', 'Rt']].resample('W-SUN').agg({'casos':np.sum, \n",
    "                                                                                                        'p_rt1': np.mean, 'Rt': np.mean})\n",
    "    data_small_cities.columns = data_small_cities.columns + f'_small'\n",
    "    \n",
    "    list_data_ep.append(data_small_cities)\n",
    "    \n",
    "    data_ep = pd.concat(list_data_ep, axis=1, join='outer')#.fillna(method='ffill')\n",
    "    \n",
    "    return data_ep \n",
    "\n",
    "\n",
    "def predictors_clim_macro(macro):\n",
    "    '''\n",
    "    This function is used to organize in a table the climate predictors related to a specific health macroregion\n",
    "    \n",
    "    :params macro: int. A four digit number\n",
    "    '''\n",
    "    geocodes, state = get_geocodes_and_state(macro)\n",
    "    \n",
    "    # get climate factors \n",
    "    df_clim = pd.read_parquet(f'/Users/eduardoaraujo/Documents/Github/paper-dengue-sc/data/climate/{state}_climate.parquet',\n",
    "                         columns = predictors_clim.append('geocodigo'))\n",
    "    \n",
    "    # select only the geocodes include in the health macroregion\n",
    "    df_clim = df_clim.loc[df_clim.geocodigo.isin(geocodes)]\n",
    "\n",
    "    df_clim = df_clim.loc[df_clim.index.year >= 2010]\n",
    "\n",
    "    del df_clim['index']\n",
    "    \n",
    "    # compute other climate features \n",
    "    df_clim['temp_mean'] = (df_clim.temp_max+df_clim.temp_min)/2\n",
    "\n",
    "    df_clim['pressao_mean'] = (df_clim.pressao_max+df_clim.pressao_min)/2\n",
    "\n",
    "    df_clim['umid_mean'] = (df_clim.umid_max+df_clim.umid_min)/2\n",
    "\n",
    "    df_clim['temp_amp'] = df_clim.temp_max-df_clim.temp_min\n",
    "        # Rainy days\n",
    "    df_clim['rainy_days'] = df_clim.precip_max > 0\n",
    "        # Humidity amplitude\n",
    "    df_clim['umid_amp'] = df_clim.umid_max - df_clim.umid_min\n",
    "\n",
    "    # agg data by weekly since that's the time scale of the cases \n",
    "    df_clim = df_clim.groupby('geocodigo').resample('W-SUN').agg({'temp_min':np.mean, 'temp_max': np.mean,\n",
    "\n",
    "                                                                'umid_min':np.mean, 'umid_max': np.mean,\n",
    "                                                                'pressao_min':np.mean, 'pressao_max': np.mean,\n",
    "                                                                'precip_tot':np.sum, 'rainy_days': np.sum,\n",
    "                                                                'temp_mean':np.mean, 'temp_amp':np.mean,\n",
    "                                                                'umid_mean': np.mean,'umid_amp': np.mean,\n",
    "                                                                'pressao_mean':np.mean}).reset_index().set_index('date')\n",
    "    \n",
    "    # split the geocodes between cities with population up and below 30k in 2022\n",
    "    g_up, g_low = split_geocodes(geocodes)\n",
    "    \n",
    "    \n",
    "    # get the predictors of each city with population above 30k\n",
    "    \n",
    "    list_data_clim = []\n",
    "\n",
    "    for g in g_up:\n",
    "\n",
    "        list_data_clim.append(transform_data(df_clim, g, 'geocodigo'))\n",
    "\n",
    "    #del df_clim['geocodigo']\n",
    "\n",
    "    #data_macro_clim = df_clim.resample('W-SUN').agg({'temp_min':np.mean, 'temp_max': np.mean,\n",
    "\n",
    "     #                                                           'umid_min':np.mean, 'umid_max': np.mean,\n",
    "      #                                                          'pressao_min':np.mean, 'pressao_max': np.mean,\n",
    "       #                                                         'precip_tot':np.sum, 'rainy_days': np.sum,\n",
    "        #                                                        'temp_mean':np.mean, 'temp_amp':np.mean,\n",
    "         #                                                       'umid_mean': np.mean,'umid_amp': np.mean,\n",
    "          #                                                      'pressao_mean':np.mean}).reset_index().set_index('date')\n",
    "\n",
    "    #data_macro_clim.columns = data_macro_clim.columns + f'_{macro}'\n",
    "\n",
    "    #list_data_clim.append(data_macro_clim)\n",
    "    \n",
    "    # aggregate the data from small cities and save the mean as predictor\n",
    "    \n",
    "    data_small_cities = df_clim.loc[df_clim.geocodigo.isin(g_low)][['temp_min','temp_max',\n",
    "                                                                'umid_min', 'umid_max',\n",
    "                                                                'pressao_min', 'pressao_max',\n",
    "                                                                'precip_tot', 'rainy_days',\n",
    "                                                                'temp_mean', 'temp_amp',\n",
    "                                                                'umid_mean', 'umid_amp',\n",
    "                                                                'pressao_mean']].resample('W-SUN').mean()\n",
    "    \n",
    "\n",
    "    data_small_cities.columns = data_small_cities.columns + f'_small'\n",
    "    \n",
    "    list_data_clim.append(data_small_cities)\n",
    "    \n",
    "    data_clim = pd.concat(list_data_clim, axis=1, join='outer').fillna(method='ffill')\n",
    "    \n",
    "    return data_clim \n",
    "\n",
    "\n",
    "def get_data_macro(macro):\n",
    "    '''\n",
    "    This function is used to organize in a table the climate and epidemiological predictors \n",
    "    related to a specific health macroregion.\n",
    "    \n",
    "    :params macro: int. A four-digit number\n",
    "    '''\n",
    "    \n",
    "    data_ep = predictors_ep_macro(macro)\n",
    "    \n",
    "    data_clim = predictors_clim_macro(macro)\n",
    "    \n",
    "    return pd.concat([data_ep, data_clim], axis = 1, join = 'outer')#.fillna(method = 'ffill')\n",
    "\n",
    "\n",
    "def predictors_ep_state(state): \n",
    "    \n",
    "    '''\n",
    "    This function is used to organize in a table the epidemiological predictors related to a specific state    \n",
    "    :params state: str. Two leters code \n",
    "    '''\n",
    "        \n",
    "    \n",
    "    # get epidemiological factors \n",
    "    df_ep = pd.read_parquet(f'/Users/eduardoaraujo/Documents/Github/paper-dengue-sc/data/cases/{state}_dengue.parquet',\n",
    "                           columns = ['data_iniSE', 'casos', 'municipio_geocodigo', 'p_rt1', 'Rt'])\n",
    "\n",
    "    df_ep = df_ep.sort_index()\n",
    "    \n",
    "    # this copy will be used to compute the target for all the state later \n",
    "    df_ep_copy = df_ep.copy()\n",
    "    \n",
    "    # link the geocode and the health macroregion code \n",
    "    df_ep = df_ep.reset_index().merge(dfs[['code_macro', 'geocode']].rename(columns = {'geocode':'municipio_geocodigo'}),\n",
    "                          on = 'municipio_geocodigo').set_index('data_iniSE')\n",
    "    \n",
    "    del df_ep['municipio_geocodigo']\n",
    "    \n",
    "    # resample the data based of the macroregion \n",
    "    df_ep = df_ep.groupby('code_macro').resample('W-SUN').agg({'casos':np.sum, \n",
    "                               'p_rt1': np.mean, \n",
    "                               'Rt': np.mean}).reset_index().set_index('data_iniSE')\n",
    "    \n",
    "    df_ep.index = pd.to_datetime(df_ep.index)\n",
    "    \n",
    "    # transform in column the data of each predictor by macroregion\n",
    "    list_data_ep = []\n",
    "\n",
    "    for m in df_ep.code_macro.unique():\n",
    "\n",
    "        list_data_ep.append(transform_data(df_ep, m, 'code_macro'))\n",
    "    \n",
    "    # get the total weekly cases of the state (it will be used as target)\n",
    "    data_state_ep = df_ep_copy[['casos']].resample('W-SUN').sum()#agg({'casos':np.sum, \n",
    "                               #'p_rt1': np.mean, \n",
    "                               #'Rt': np.mean})\n",
    "\n",
    "    data_state_ep.columns = data_state_ep.columns + f'_{state}'\n",
    "\n",
    "    list_data_ep.append(data_state_ep)\n",
    "    \n",
    "    # final dataframe\n",
    "    data_ep = pd.concat(list_data_ep, axis=1, join='outer')#.fillna(method='ffill')\n",
    "    \n",
    "    return data_ep \n",
    "\n",
    "def predictors_clim_state(state):\n",
    "    '''\n",
    "    This function is used to organize in a table the climate predictors related to a specific state    \n",
    "    :params state: str. Two leters code \n",
    "    '''\n",
    "    \n",
    "    # get climate factors \n",
    "    df_clim = pd.read_parquet(f'/Users/eduardoaraujo/Documents/Github/paper-dengue-sc/data/climate/{state}_climate.parquet',\n",
    "                         columns = predictors_clim.append('geocodigo'))\n",
    "\n",
    "    df_clim = df_clim.loc[df_clim.index.year >= 2010]\n",
    "    \n",
    "    del df_clim['index']\n",
    "\n",
    "    df_clim['temp_mean'] = (df_clim.temp_max+df_clim.temp_min)/2\n",
    "\n",
    "    df_clim['pressao_mean'] = (df_clim.pressao_max+df_clim.pressao_min)/2\n",
    "\n",
    "    df_clim['umid_mean'] = (df_clim.umid_max+df_clim.umid_min)/2\n",
    "\n",
    "    df_clim['temp_amp'] = df_clim.temp_max-df_clim.temp_min\n",
    "        # Rainy days\n",
    "    df_clim['rainy_days'] = df_clim.precip_max > 0\n",
    "        # Humidity amplitude\n",
    "    df_clim['umid_amp'] = df_clim.umid_max - df_clim.umid_min\n",
    "\n",
    "    # link the geocode and the health macroregion code \n",
    "    \n",
    "    df_clim = df_clim.reset_index().merge(dfs[['code_macro', 'geocode']].rename(columns = {'geocode':'geocodigo'}),\n",
    "                          on = 'geocodigo').set_index('date')\n",
    "\n",
    "    del df_clim['geocodigo']\n",
    "\n",
    "    # resample the data based of the macroregion \n",
    "    df_clim = df_clim.groupby('code_macro').resample('W-SUN').agg({'temp_min':np.mean, 'temp_max': np.mean,\n",
    "\n",
    "                                                                'umid_min':np.mean, 'umid_max': np.mean,\n",
    "                                                                'pressao_min':np.mean, 'pressao_max': np.mean,\n",
    "                                                                'precip_tot':np.sum, 'rainy_days': np.sum,\n",
    "                                                                'temp_mean':np.mean, 'temp_amp':np.mean,\n",
    "                                                                'umid_mean': np.mean,'umid_amp': np.mean,\n",
    "                                                                'pressao_mean':np.mean}).reset_index().set_index('date')\n",
    "\n",
    "    # transform in column the data of each predictor by macroregion\n",
    "    list_data_clim = []\n",
    "\n",
    "    for m in df_clim.code_macro.unique():\n",
    "\n",
    "        list_data_clim.append(transform_data(df_clim, m, 'code_macro'))\n",
    "    \n",
    "\n",
    "    #data_state_clim = df_clim_copy.resample('W-SUN').agg({'temp_min':np.mean, 'temp_max': np.mean,\n",
    "\n",
    "     #                                                           'umid_min':np.mean, 'umid_max': np.mean,\n",
    "      #                                                          'pressao_min':np.mean, 'pressao_max': np.mean,\n",
    "       #                                                         'precip_tot':np.sum, 'rainy_days': np.sum,\n",
    "        #                                                        'temp_mean':np.mean, 'temp_amp':np.mean,\n",
    "         #                                                       'umid_mean': np.mean,'umid_amp': np.mean,\n",
    "          #                                                      'pressao_mean':np.mean}).reset_index().set_index('date')\n",
    "\n",
    "    #data_state_clim.columns = data_state_clim.columns + f'_{state}'\n",
    "\n",
    "    #list_data_clim.append(data_state_clim)\n",
    "\n",
    "    # final dataframe\n",
    "    data_clim = pd.concat(list_data_clim, axis=1, join='outer').fillna(method='ffill')\n",
    "    \n",
    "    return data_clim \n",
    "\n",
    "\n",
    "def get_data_state(state):\n",
    "    '''\n",
    "    This function is used to organize in a table the climate and epidemiological predictors \n",
    "    related to a specific state.\n",
    "    \n",
    "    :params macro: int. A four digit number\n",
    "    '''\n",
    "    \n",
    "    data_ep = predictors_ep_state(state)\n",
    "    \n",
    "    data_clim = predictors_clim_state(state)\n",
    "    \n",
    "    return pd.concat([data_ep, data_clim], axis = 1, join = 'outer')#.fillna(method = 'ffill')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c739fe7",
   "metadata": {},
   "source": [
    "Get data for all macro in MG: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21ecaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for macro in dfs.loc[dfs.state=='MG'].code_macro.unique():\n",
    "\n",
    "    df1 = get_data_macro(macro)\n",
    "    \n",
    "    df1.to_csv(f'../data/dengue_{macro}.csv')\n",
    "    \n",
    "    df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8877a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casos_3101</th>\n",
       "      <th>p_rt1_3101</th>\n",
       "      <th>Rt_3101</th>\n",
       "      <th>casos_3102</th>\n",
       "      <th>p_rt1_3102</th>\n",
       "      <th>Rt_3102</th>\n",
       "      <th>casos_3103</th>\n",
       "      <th>p_rt1_3103</th>\n",
       "      <th>Rt_3103</th>\n",
       "      <th>casos_3104</th>\n",
       "      <th>...</th>\n",
       "      <th>umid_max_3114</th>\n",
       "      <th>pressao_min_3114</th>\n",
       "      <th>pressao_max_3114</th>\n",
       "      <th>precip_tot_3114</th>\n",
       "      <th>rainy_days_3114</th>\n",
       "      <th>temp_mean_3114</th>\n",
       "      <th>temp_amp_3114</th>\n",
       "      <th>umid_mean_3114</th>\n",
       "      <th>umid_amp_3114</th>\n",
       "      <th>pressao_mean_3114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.103580</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>1.002990</td>\n",
       "      <td>23.623390</td>\n",
       "      <td>105</td>\n",
       "      <td>25.975808</td>\n",
       "      <td>10.060156</td>\n",
       "      <td>71.815624</td>\n",
       "      <td>40.575911</td>\n",
       "      <td>1.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.234251</td>\n",
       "      <td>0.997709</td>\n",
       "      <td>1.001661</td>\n",
       "      <td>144.832569</td>\n",
       "      <td>245</td>\n",
       "      <td>26.172300</td>\n",
       "      <td>9.370447</td>\n",
       "      <td>73.524498</td>\n",
       "      <td>35.419506</td>\n",
       "      <td>0.999685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-17</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.154297</td>\n",
       "      <td>0.999295</td>\n",
       "      <td>1.003492</td>\n",
       "      <td>41.721230</td>\n",
       "      <td>245</td>\n",
       "      <td>26.955346</td>\n",
       "      <td>10.111888</td>\n",
       "      <td>68.444813</td>\n",
       "      <td>39.418967</td>\n",
       "      <td>1.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-24</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1673.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.084402</td>\n",
       "      <td>0.997927</td>\n",
       "      <td>1.002659</td>\n",
       "      <td>58.044680</td>\n",
       "      <td>245</td>\n",
       "      <td>27.029704</td>\n",
       "      <td>10.326734</td>\n",
       "      <td>67.026808</td>\n",
       "      <td>40.115189</td>\n",
       "      <td>1.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-31</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.693930</td>\n",
       "      <td>0.998273</td>\n",
       "      <td>1.002670</td>\n",
       "      <td>40.796540</td>\n",
       "      <td>245</td>\n",
       "      <td>26.911134</td>\n",
       "      <td>10.386157</td>\n",
       "      <td>65.211321</td>\n",
       "      <td>38.965219</td>\n",
       "      <td>1.000471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            casos_3101  p_rt1_3101  Rt_3101  casos_3102  p_rt1_3102  Rt_3102  \\\n",
       "2010-01-03        12.0         0.0      0.0         4.0         0.0      0.0   \n",
       "2010-01-10        10.0         0.0      0.0         3.0         0.0      0.0   \n",
       "2010-01-17        28.0         0.0      0.0         6.0         0.0      0.0   \n",
       "2010-01-24        55.0         0.0      0.0         6.0         0.0      0.0   \n",
       "2010-01-31        74.0         0.0      0.0         2.0         0.0      0.0   \n",
       "\n",
       "            casos_3103  p_rt1_3103  Rt_3103  casos_3104  ...  umid_max_3114  \\\n",
       "2010-01-03       614.0         0.0      0.0        74.0  ...      92.103580   \n",
       "2010-01-10       892.0         0.0      0.0        78.0  ...      91.234251   \n",
       "2010-01-17      1092.0         0.0      0.0        85.0  ...      88.154297   \n",
       "2010-01-24      1673.0         0.0      0.0        84.0  ...      87.084402   \n",
       "2010-01-31      2298.0         0.0      0.0        34.0  ...      84.693930   \n",
       "\n",
       "            pressao_min_3114  pressao_max_3114  precip_tot_3114  \\\n",
       "2010-01-03          0.999013          1.002990        23.623390   \n",
       "2010-01-10          0.997709          1.001661       144.832569   \n",
       "2010-01-17          0.999295          1.003492        41.721230   \n",
       "2010-01-24          0.997927          1.002659        58.044680   \n",
       "2010-01-31          0.998273          1.002670        40.796540   \n",
       "\n",
       "            rainy_days_3114  temp_mean_3114  temp_amp_3114  umid_mean_3114  \\\n",
       "2010-01-03              105       25.975808      10.060156       71.815624   \n",
       "2010-01-10              245       26.172300       9.370447       73.524498   \n",
       "2010-01-17              245       26.955346      10.111888       68.444813   \n",
       "2010-01-24              245       27.029704      10.326734       67.026808   \n",
       "2010-01-31              245       26.911134      10.386157       65.211321   \n",
       "\n",
       "            umid_amp_3114  pressao_mean_3114  \n",
       "2010-01-03      40.575911           1.001001  \n",
       "2010-01-10      35.419506           0.999685  \n",
       "2010-01-17      39.418967           1.001393  \n",
       "2010-01-24      40.115189           1.000293  \n",
       "2010-01-31      38.965219           1.000471  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 'MG'\n",
    "\n",
    "df2 = get_data_state(state)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf058bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(f'../data/dengue_{state}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161fe55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010-01-03    2794.0\n",
       "2010-01-10    3729.0\n",
       "2010-01-17    4656.0\n",
       "2010-01-24    6195.0\n",
       "2010-01-31    7179.0\n",
       "               ...  \n",
       "2023-12-03    6408.0\n",
       "2023-12-10    6837.0\n",
       "2023-12-17    4178.0\n",
       "2023-12-24     998.0\n",
       "2023-12-31       NaN\n",
       "Freq: W-SUN, Name: casos_MG, Length: 731, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['casos_MG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fbf68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
